{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "bbf726d0b1f933513ea74365d39462104047c8d9bd4636ddbcd10a56e8c32395"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "### What's wrong with Linear\n",
    "* 4 hidden layers: \\[784,256,256,256,10\\]\n",
    "    * 390K parameters\n",
    "    * 1.6MB memory\n",
    "    * 80386"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Convolution\n",
    "* Receptive Field\n",
    "* Weight sharing\n",
    "    * e.g. LeNet-5\n",
    "    * ~60K parameters\n",
    "    * 6 Layers\n",
    "* Convolution Operation\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Notation\n",
    "* Input_channels: e.g. 3 for RGB\n",
    "* Kernel_channels: number of kernels\n",
    "* Kernel_size: size of kernel e.g. 3*3\n",
    "* Stride: steps of kernel moving\n",
    "* Padding: number of zeros adding around input\n",
    "\n",
    "e.g.\n",
    "\n",
    "* x: \\[b,3,28,28\\]\n",
    "* one k: \\[3,3,3\\]\n",
    "* multi-k: \\[16,3,3,3\\]\n",
    "* bias: \\[16\\]\n",
    "* out: \\[b,16,28,28\\]\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 26, 26])"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "layer = torch.nn.Conv2d(1,3,kernel_size=3,stride=1,padding=0)\n",
    "x = torch.rand(1,1,28,28)\n",
    "out = layer.forward(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 28, 28])"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "layer = torch.nn.Conv2d(1,3,kernel_size=3,stride=1,padding=1)\n",
    "out = layer.forward(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 14, 14])"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "layer = torch.nn.Conv2d(1,3,kernel_size=3,stride=2,padding=1)\n",
    "out = layer.forward(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 14, 14])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "out = layer(x) # __call__ hooks\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[[[-0.0548,  0.3053, -0.0196],\n",
       "          [ 0.0065,  0.1361, -0.1108],\n",
       "          [-0.2680,  0.1364,  0.2705]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0743,  0.1881,  0.2415],\n",
       "          [ 0.0644, -0.2529,  0.1107],\n",
       "          [ 0.1143,  0.0075, -0.1950]]],\n",
       "\n",
       "\n",
       "        [[[-0.0960, -0.2884, -0.1681],\n",
       "          [ 0.2984,  0.1852,  0.1816],\n",
       "          [ 0.2769,  0.2022, -0.0348]]]], requires_grad=True)"
      ]
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(torch.Size([3, 1, 3, 3]), torch.Size([3]))"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "layer.weight.shape, layer.bias.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 26, 26])"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "# another low_level way\n",
    "w = torch.rand(16,3,5,5)\n",
    "b = torch.rand(16)\n",
    "x = torch.randn(1,3,28,28)\n",
    "out = torch.nn.functional.conv2d(x,w,b,stride=1,padding=1)\n",
    "out.shape"
   ]
  },
  {
   "source": [
    "## Pooling\n",
    "* Downsample\n",
    "* Upsample\n",
    "* Max Pooling: max pool with 2*2 filters and stride 2 from rectified map\n",
    "    * Average"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 26, 26])"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "x = out\n",
    "layer = torch.nn.MaxPool2d(2,stride=2)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 13, 13])"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "# max pooling\n",
    "out = layer(x)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 13, 13])"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "# average pooling\n",
    "out = torch.nn.functional.avg_pool2d(x,2,stride=2)\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 52, 52])"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "# upsample - interpolate\n",
    "out = torch.nn.functional.interpolate(x,scale_factor=2,mode='nearest')\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([1, 16, 78, 78])"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "out = torch.nn.functional.interpolate(x,scale_factor=3,mode='nearest')\n",
    "out.shape"
   ]
  },
  {
   "source": [
    "## Batch_Norm\n",
    "> avoid gradient dispersion or explosion e.g. sigmoid\n",
    "\n",
    "* feature scaling\n",
    "\n",
    "* Batch \\[N,C,H*W\\] norm e.g.\\[6,3,784\\]\n",
    "    * take means from every **C_i** of **C**\n",
    "    > C_0 -> mean_0, C_1 -> mean_1, C_2 -> mean_2\n",
    "    * mini-batch mean -> mini-batch variance -> normalize -> scale and shift \n",
    "* Layer norm\n",
    "    * take means from every **N_i** of **N**\n",
    "    > N_0 -> mean_0, ... , N_5 -> mean_5\n",
    "* Instance norm\n",
    "    * take means from every instance\n",
    "\n",
    "### Advantages\n",
    "* Converge faster\n",
    "* Better performance\n",
    "* Robust\n",
    "    * stable\n",
    "    * larger learning rate"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Unit\n",
    "* conv2d + (batch_norm + pool + ReLU)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(tensor([0.0498, 0.0499, 0.0498, 0.0501, 0.0500, 0.0500, 0.0500, 0.0499, 0.0500,\n",
       "         0.0500, 0.0499, 0.0499, 0.0501, 0.0502, 0.0500, 0.0501]),\n",
       " tensor([0.9083, 0.9084, 0.9083, 0.9084, 0.9084, 0.9083, 0.9083, 0.9083, 0.9083,\n",
       "         0.9083, 0.9083, 0.9083, 0.9083, 0.9083, 0.9084, 0.9083]),\n",
       " Parameter containing:\n",
       " tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        requires_grad=True))"
      ]
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "# BatchNorm1d\n",
    "x = torch.rand(100,16,784)\n",
    "layer = torch.nn.BatchNorm1d(16) # number of channals\n",
    "out = layer(x)\n",
    "layer.running_mean, layer.running_var, layer.weight, layer.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'training': True,\n",
       " '_parameters': OrderedDict([('weight', Parameter containing:\n",
       "               tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "                      requires_grad=True)),\n",
       "              ('bias',\n",
       "               Parameter containing:\n",
       "               tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                      requires_grad=True))]),\n",
       " '_buffers': OrderedDict([('running_mean',\n",
       "               tensor([-0.0016,  0.0036,  0.0071,  0.0058,  0.0185, -0.0164,  0.0034, -0.0005,\n",
       "                       -0.0035, -0.0070, -0.0060,  0.0083,  0.0095, -0.0077,  0.0038, -0.0055])),\n",
       "              ('running_var',\n",
       "               tensor([0.9921, 0.9902, 0.9935, 0.9979, 1.0072, 0.9997, 0.9847, 0.9753, 1.0047,\n",
       "                       0.9902, 0.9924, 0.9950, 1.0086, 0.9834, 0.9894, 1.0026])),\n",
       "              ('num_batches_tracked', tensor(1))]),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict(),\n",
       " 'num_features': 16,\n",
       " 'eps': 1e-05,\n",
       " 'momentum': 0.1,\n",
       " 'affine': True,\n",
       " 'track_running_stats': True}"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "# BatchNorm2d\n",
    "x = torch.randn(4,16,7,7)\n",
    "layer = torch.nn.BatchNorm2d(16)\n",
    "out = layer(x)\n",
    "vars(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'training': False,\n",
       " '_parameters': OrderedDict([('weight',\n",
       "               Parameter containing:\n",
       "               tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "                      requires_grad=True)),\n",
       "              ('bias',\n",
       "               Parameter containing:\n",
       "               tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "                      requires_grad=True))]),\n",
       " '_buffers': OrderedDict([('running_mean',\n",
       "               tensor([-0.0016,  0.0036,  0.0071,  0.0058,  0.0185, -0.0164,  0.0034, -0.0005,\n",
       "                       -0.0035, -0.0070, -0.0060,  0.0083,  0.0095, -0.0077,  0.0038, -0.0055])),\n",
       "              ('running_var',\n",
       "               tensor([0.9921, 0.9902, 0.9935, 0.9979, 1.0072, 0.9997, 0.9847, 0.9753, 1.0047,\n",
       "                       0.9902, 0.9924, 0.9950, 1.0086, 0.9834, 0.9894, 1.0026])),\n",
       "              ('num_batches_tracked', tensor(1))]),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict(),\n",
       " 'num_features': 16,\n",
       " 'eps': 1e-05,\n",
       " 'momentum': 0.1,\n",
       " 'affine': True,\n",
       " 'track_running_stats': True}"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "layer.eval()\n",
    "vars(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}